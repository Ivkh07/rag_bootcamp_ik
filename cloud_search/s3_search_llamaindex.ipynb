{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214d4de8-3a05-43dd-8a44-82c22570a553",
   "metadata": {},
   "source": [
    "# Amazon AWS S3 Search with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LlamaIndex](https://www.llamaindex.ai/) library to run a text-generation request against [Cohere's](https://cohere.com/) API, then augment that request using documents stored in an Amazon AWS S3 bucket.\n",
    "\n",
    "**Requirements:**\n",
    "- You will need an access key to Cohere's API key, which you can sign up for at (https://dashboard.cohere.com/welcome/login). A free trial account will suffice, but will be limited to a small number of requests.\n",
    "- After obtaining this key, store it in plain text in your home in directory in the `~/.cohere.key` file.\n",
    "- You will also need an Amazon AWS account, with some documents stored in a S3 bucket.\n",
    "- Store your AWS credentials in a text file at `~/.aws/credentials`. This file must use the following format:\n",
    "  \n",
    "  ```\n",
    "    [default]\n",
    "    aws_access_key_id = YOUR_ACCESS_KEY\n",
    "    aws_secret_access_key = YOUR_SECRET_KEY\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from llama_index import download_loader, ServiceContext, VectorStoreIndex\n",
    "from llama_index.embeddings.cohereai import CohereEmbedding\n",
    "from llama_index.llms import Cohere\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "Set up some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "Make sure other necessary items are in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74b61e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the environment\n",
    "try:\n",
    "    os.environ[\"COHERE_API_KEY\"] = open(Path.home() / \".cohere.key\", \"r\").read().strip()\n",
    "    os.environ[\"CO_API_KEY\"] = os.environ[\"COHERE_API_KEY\"]\n",
    "except Exception:\n",
    "    sys.exit(f\"Unable to read your Cohere API key. Make sure this is stored in a text file in your home directory at ~/.cohere.key\\n\")\n",
    "\n",
    "# Make sure that the AWS credentials are stored in ~/.aws/credentials\n",
    "try:\n",
    "    aws_credentials_file = Path.home() / \".aws/credentials\"\n",
    "    assert aws_credentials_file.exists()\n",
    "except:\n",
    "    sys.exit(f\"Unable to find your AWS credentials file at {aws_credentials_file}. Make sure this file exists and contains your AWS credentials.\\n\")\n",
    "\n",
    "# Make sure the AWS credentials are stored in the correct format\n",
    "try:\n",
    "    aws_credentials = open(aws_credentials_file, \"r\").read().strip()\n",
    "    assert aws_credentials.startswith(\"[default]\")\n",
    "    assert \"aws_access_key_id\" in aws_credentials\n",
    "    assert \"aws_secret_access_key\" in aws_credentials\n",
    "except Exception:\n",
    "    sys.exit(f\"\"\"Unable to load AWS credentials. Make sure your ~/.aws/credentials file is in the following format:\n",
    "[default]\n",
    "aws_access_key_id = YOUR_ACCESS_KEY\n",
    "aws_secret_access_key = YOUR_SECRET_KEY\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking the Cohere LLM a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's basic knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is very domain-specific that it won't know the answer to. Let's use an obscure research project we don't expect it to know the answer to.\n",
    "\n",
    "\"*Describe the goals of the OpenNF project.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Describe the goals of the OpenNF project.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295a6a9-76bc-4779-8346-c1cfdea30a3b",
   "metadata": {},
   "source": [
    "## Send the generation request to Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3a3949-bc8f-4244-ab12-4759e296aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The OpenNF project is a collaborative initiative aimed at promoting the development and adoption of Natural Language Processing models (NLP) that are open source, transparent, and accessible to a broader range of users. \n",
      "\n",
      "Specifically, the project has the following goals: \n",
      "\n",
      "1. **Inclusivity:** The project aims to make state-of-the-art NLP tools and datasets accessible to researchers, developers, and organizations who may not have the resources to afford proprietary models and subscriptions offered by large tech companies. The project is particularly keen on ensuring that underserved languages and dialects benefit from advances in NLP. \n",
      "\n",
      "2. **Transparency and Trustworthiness:** OpenNF proponents want to address concerns surrounding the lack of transparency in many of today's NLP models. They believe that openness in terms of data collection, model training, and algorithmic decision-making is crucial for building confidence, addressing biases, and ensuring ethical use of these technologies. \n",
      "\n",
      "3. **Collaboration and Innovation:** OpenNF is envisioned as a platform where researchers and developers can collaborate, share knowledge, and build upon each other's work. The project encourages the open exchange of ideas, algorithms, and datasets to foster innovation and avoid redundant efforts. \n",
      "\n",
      "4. **Standardization and Reproducibility:** To facilitate interoperability and reproducibility, the project may develop or recommend standardized methodologies, metrics, and benchmarks for evaluating NLP models. This will ensure that results are consistent and can be replicated across different platforms. \n",
      "\n",
      "Overall, the OpenNF project wants to make cutting-edge NLP tools accessible to a wide range of users, while promoting transparency, collaboration, and innovation in the NLP field. \n"
     ]
    }
   ],
   "source": [
    "llm = Cohere(api_key=os.environ[\"COHERE_API_KEY\"])\n",
    "result = llm.complete(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Cohere will occasionally get this right *(TODO: find a better example!)* but usually gets it wrong. The correct answer is that OpenNF is NFV+SDN networking project that focuses on state transfer in virtualized network environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Retrieve some documents from an Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "I've added a few PDF documents related to the OpenNF project in an Amazon S3 bucket:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19ee43d-b312-4e06-a2a0-aae2e6f566d2",
   "metadata": {},
   "source": [
    "![aws-s3-snapshot](imgs/aws-s3-snapshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a865f-38f6-4db9-bb98-03046403ccc6",
   "metadata": {},
   "source": [
    "### Load these documents using S3Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb063591-d7a8-44bd-b160-c993df65280b",
   "metadata": {},
   "source": [
    "Fortunately, there is a simple S3 utility available via [LlamaHub](https://www.llamahub.ai/), a registry of open-source data connectors that you can easily plug into any LlamaIndex application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3Reader = download_loader(\"S3Reader\")\n",
    "loader = S3Reader(bucket='vector-rag-bootcamp-v2')\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2f772-e126-4ef9-9b10-fafc150f2ec4",
   "metadata": {},
   "source": [
    "## Define Embeddings Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3660c8d9-949f-4e27-ab16-cf01dcfa9c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /tmp/JMzMIxqc706ehpGd/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "embed_model = CohereEmbedding(\n",
    "    model_name=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\"\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7545e",
   "metadata": {},
   "source": [
    "## Embeddings Store, Retrieval and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a89095-98f8-40fb-9270-49c93744296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2a11f2586a40fca5a107a96c00503d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189fd049a1b0446a913d3396d92af1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the base vector store retriever\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context, show_progress=True)\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n",
    "search_query_retriever = index.as_retriever(service_context=service_context)\n",
    "search_query_retrieved_nodes = search_query_retriever.retrieve(query)\n",
    "\n",
    "# Use a reranker to identify the most closest match\n",
    "reranker = CohereRerank()\n",
    "query_engine = index.as_query_engine(\n",
    "    node_postprocessors = [reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "## Lastly, send the augmented request to Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23499f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goals of the OpenNF project are to provide critical mechanisms to the SDN+NFV landscape and deliver a high-calibre solution to problems that are rapidly becoming evident. The project is aimed at developing and commercializing the OpenNF technology through various milestones and patents filed through WARF.\n"
     ]
    }
   ],
   "source": [
    "result = query_engine.query(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_dataloaders",
   "language": "python",
   "name": "rag_dataloaders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
