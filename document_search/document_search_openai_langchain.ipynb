{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "# OpenAI Document Search with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [langchain](https://python.langchain.com/docs/get_started/introduction) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using the text stored in a collection of local PDF documents.\n",
    "\n",
    "### <u>Requirements</u>\n",
    "1. As you will accessing the LLMs and embedding models through Vector AI Engineering's Kaleidoscope Service (Vector Inference + Autoscaling), you will need to request a KScope API Key:\n",
    "- If using **VPN**:\n",
    "  \n",
    "  Visit [https://kscope.vectorinstitute.ai/](https://kscope.vectorinstitute.ai/) and select *Request API Key*.\n",
    "  \n",
    "- If running **without VPN**:\n",
    "\n",
    "  Run the following command (replace ```<user_id>``` and ```<password>```) from **within the cluster** to obtain the API Key. The ```access_token``` in the output is your KScope API Key.\n",
    "  ```bash\n",
    "  curl -X POST -d \"grant_type=password\" -d \"username=<user_id>\" -d \"password=<password>\" https://kscope.vectorinstitute.ai/token\n",
    "  ```\n",
    "2. After obtaining the `.env` configurations, make sure to create the ```.kscope.env``` file in your home directory (```/h/<user_id>```) and set the following env variables:\n",
    "- For local models through Kaleidoscope (KScope):\n",
    "    ```bash\n",
    "    export OPENAI_BASE_URL=\"https://kscope.vectorinstitute.ai/v1\"\n",
    "    export OPENAI_API_KEY=<kscope_api_key>\n",
    "    ```\n",
    "- For OpenAI models:\n",
    "   ```bash\n",
    "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"\n",
    "   export OPENAI_API_KEY=<openai_api_key>\n",
    "   ```\n",
    "3. (Optional) Upload some pdf files into the `source_documents` subfolder under this notebook. We have already provided some sample pdfs, but feel free to replace these with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a7448",
   "metadata": {},
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e70d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add root folder of the rag_bootcamp repo to PYTHONPATH\n",
    "current_dir = Path().resolve()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f629efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_secrets import load_env_file\n",
    "load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e0bec6-a89c-4fca-a218-c784ec18e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "EMBEDDING_BASE_URL = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "#### Make sure other necessary items are in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b61e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for the source_documents folder and make sure there is at least 1 pdf file here\n",
    "contains_pdf = False\n",
    "directory_path = \"./source_documents\"\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"ERROR: The {directory_path} subfolder must exist under this notebook\")\n",
    "for filename in os.listdir(directory_path):\n",
    "    contains_pdf = True if \".pdf\" in filename else contains_pdf\n",
    "if not contains_pdf:\n",
    "    print(f\"ERROR: The {directory_path} subfolder must contain at least one .pdf file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c93ad-fe81-4acd-9ea3-eca9b425ee9a",
   "metadata": {},
   "source": [
    "#### Set LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2553d130-5b02-4852-928f-beb7ecd05d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "EMBEDDING_MODEL_NAME = \"e5-mistral-7b-instruct\" # \"text-embedding-3-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking OpenAI a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's basic knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is very domain-specific that it won't know the answer to. A good example would an obscure detail buried deep within a company's annual report. For example:\n",
    "\n",
    "\"*How many Vector scholarships in AI were awarded in 2022?*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How many Vector scholarships in AI were awarded in 2022?\"\n",
    "query = \"How many AI master's students began their studies in 2021-22?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a22c5",
   "metadata": {},
   "source": [
    "## Now send the query to KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00061d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/projects/aieng/public/rag_bootcamp/envs/rag_dataloaders/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "Unfortunately, I'm a large language model, I don't have direct access to real-time data or specific statistics on the number of AI master's students who began their studies in 2021-22. The number of students varies widely depending on the country, institution, and program.\n",
      "\n",
      "However, I can suggest some possible sources where you may be able to find the information you're looking for:\n",
      "\n",
      "1. **National statistics offices**: You can try contacting the national statistics office of the country where you're interested in finding the data. For example, in the United States, you can contact the National Center for Education Statistics (NCES).\n",
      "2. **University websites**: Many universities publish information on their website about the number of students enrolled in their master's programs, including AI programs. You can try searching for the websites of universities that offer AI master's programs and see if they provide this information.\n",
      "3. **Professional organizations**: Organizations like the Association for the Advancement of Artificial Intelligence (AAAI) or the International Joint Conference on Artificial Intelligence (IJCAI) may have data on the number of students pursuing AI-related master's degrees.\n",
      "4. **Government databases**: Databases like the Integrated Postsecondary Education Data System (IPEDS) in the United States or the European Union's European Higher Education Area (EHEA) may provide information on student enrollment trends, including for AI master's programs.\n",
      "\n",
      "If you provide me with more specific information about the country or region you're interested in, I may be able to help you find the information you're looking for.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=GENERATOR_MODEL_NAME, base_url=GENERATOR_BASE_URL, api_key=OPENAI_API_KEY)\n",
    "message = [\n",
    "    HumanMessage(\n",
    "        content=query\n",
    "    )\n",
    "]\n",
    "try:\n",
    "    result = llm(message)\n",
    "    print(f\"Result: \\n\\n{result.content}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not yet ready.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Without additional information, Llama-3.1 is unable to answer the question correctly. **Vector in fact awarded 109 AI scholarships in 2022.** Fortunately, we do have that information available in Vector's 2021-22 Annual Report, which is available in the `source_documents` folder. Let's see how we can use RAG to augment our question with a document search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c10989-e7cf-4065-bb99-5b22030bb7e9",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Load and store the documents from source_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Start by reading in all the PDF files from `source_documents`, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 42\n",
      "Number of text chunks: 228\n",
      "Setting up the embeddings model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load the pdfs\n",
    "directory_path = \"./source_documents\"\n",
    "loader = PyPDFDirectoryLoader(directory_path)\n",
    "docs = loader.load()\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")\n",
    "\n",
    "# Define the embeddings model\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "print(f\"Setting up the embeddings model...\")\n",
    "embeddings = OpenAIEmbeddings(base_url=EMBEDDING_BASE_URL, model=EMBEDDING_MODEL_NAME, api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(f\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7545e",
   "metadata": {},
   "source": [
    "# Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc16fe",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1048c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "ADVANCING LEADING AI RESEARCH BY \n",
      "HARNESSING VECTOR’S ENGINEERING RESOURCES \n",
      "This year, the AI Engineering team worked directly \n",
      "with researchers and their labs, exploring their specifc topics and collaborating with them to build and engineer software solutions and tools to address the technological barriers limiting their work. \n",
      "Following a successful pilot project in 2020–21,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "engineering. Through workshops, graduate studies and internship placements with government and other public health partners, AI4PH will enable future public health AI specialists to harness real-time data processing, analysis, and visualization from broad and specifc data sources to gain a better understanding of what is happening in the population. NEW CHIEF DATA OFFICER ROLE\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "that TELUS applied to their data centre cooling project (see p. 14), Vector’s AI Engineering experts worked closely with TELUS on making the models available to a wider audience by publishing the work on an open-source platform. \n",
      "Similarly, the team also collaborated with researchers to \n",
      "share Vector-led research in Parameter Reduction for unseen deep architecture work through open-source. \n",
      "FOSTERING NEW WAYS TO DEPLOY AI TO \n",
      "ADDRESS CLIMATE CHANGE \n",
      "In addition to fostering responsible and trustworthy\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Following this year’s AI for Clinician Champions \n",
      "Program cycle, some participants are already working to implement AI in their hospitals. As one participant stated: “Having the clinicians empowered with this information will help us leverage the power of AI in a responsible and ethical way to solve the ‘last mile’ problems we are currently facing.” \n",
      "Accelerating the appropriate adoption of AI in health\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "Talent and Research was renewed in the federal Budget 2021, and funding support associated with that renewal is expected to begin in 2022–23. The federal Budget 2021 also announced support for each of the national AI institutes to accelerate the translation of AI research into commercial or other innovations, and this funding started at the end of 2021–22. \n",
      "The Vector Institute’s audited fnancial statements for \n",
      "the 2021–22 fscal year are available on our website . \n",
      "STATEMENT OF FINANCIAL POSITION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "• 170 participants engaged in immersive three-day sessions on such topics as Privacy Enhancing Techniques (PETs) and Forecasting with Deep Learning, from which the code was shared via open source \n",
      "“Vector’s [Forecasting with Deep Learning] bootcamp, along with the prep and post work, helped to compress about six months of work into about 4-6 weeks and helped our team to rapidly progress through the initial project phase.” \n",
      "Industry sponsor participant \n",
      "SECTOR-SPECIFIC INTRODUCTION TO AI PROGRAMS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "17 \n",
      " \n",
      "MEET VECTOR’S WORLD -\n",
      "CLASS AI RESEARCH \n",
      "COMMUNITY \n",
      "Vector is advancing its goal of becoming a Top 10 global \n",
      "centre for AI research by attracting the world’s most accomplished, ambitious, and innovative researchers who are unlocking new achievements across a wide range of AI and machine learning topics. \n",
      "714 Members of the Vector research \n",
      "community, comprising: \n",
      "35 Faculty Members including  \n",
      "32 Canada CIFAR AI Chairs \n",
      "103 F\n",
      "aculty Afliates \n",
      "51 Postdoctoral Fellows \n",
      "410 G\n",
      "raduate Researchers\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "“This study is a tangible example of how AI can help improve lives. It also demonstrates how AI specialists, corporate, and health sectors can work together and share their expertise to help address some of the most worrisome outcomes of COVID-19.” \n",
      "Cameron Schuler, Vector’s Chief Commercialization Ofcer \n",
      "& Vice President, Industry Innovation \n",
      "DATASET SHIFT\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "“You get an immediate concrete beneft when people work on a project together with guidance, and guided by Vector, they’re steered in the right direction. There’s hands-on exposure to techniques and technologies.” \n",
      "Andrew Brown, Senior Director of Data Science and AI \n",
      "Research with CIBC, one of the project’s participants\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "has played an instrumental role in expanding graduate teaching, learning, and research opportunities in AI at Queen’s University.” \n",
      "Dr. Fahim Quadir, Vice-Provost and Dean, School of \n",
      "Graduate Studies & Professor of Global Developmental Studies, Queen’s University PRACTICAL, HANDS-ON \n",
      "PROGRAMMING TO FOSTER WORKFORCE SKILLS AND EXPERIENCE \n",
      "Throughout the year, students beneft from Vector-led\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "    \n",
    "    # Retrieve the most relevant context from the vector store based on the query\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    pretty_print_docs(docs)\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {EMBEDDING_MODEL_NAME} is not yet ready.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008507b",
   "metadata": {},
   "source": [
    "These results seem to somewhat match our original query, but we still can't seem to find the information we're looking for. Let's try sending our LLM query again including these results, and see what it comes up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23499f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/projects/aieng/public/rag_bootcamp/envs/rag_dataloaders/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending the RAG generation with query: How many AI master's students began their studies in 2021-22?\n",
      "Result:\n",
      "\n",
      "I don't know. The provided text does not mention the number of AI master's students who began their studies in 2021-22.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sending the RAG generation with query: {query}\")\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever)\n",
    "print(f\"Result:\\n\\n{qa.run(query=query)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea847fe",
   "metadata": {},
   "source": [
    "# Reranking: Improve the ordering of the document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24dd59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(base_url=EMBEDDING_BASE_URL, model=EMBEDDING_MODEL_NAME, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.66)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter, base_retriever=retriever\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20a66b",
   "metadata": {},
   "source": [
    "Now let's see what the reranked results look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "961dda63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "ADVANCING LEADING AI RESEARCH BY \n",
      "HARNESSING VECTOR’S ENGINEERING RESOURCES \n",
      "This year, the AI Engineering team worked directly \n",
      "with researchers and their labs, exploring their specifc topics and collaborating with them to build and engineer software solutions and tools to address the technological barriers limiting their work. \n",
      "Following a successful pilot project in 2020–21,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Talent and Research was renewed in the federal Budget 2021, and funding support associated with that renewal is expected to begin in 2022–23. The federal Budget 2021 also announced support for each of the national AI institutes to accelerate the translation of AI research into commercial or other innovations, and this funding started at the end of 2021–22. \n",
      "The Vector Institute’s audited fnancial statements for \n",
      "the 2021–22 fscal year are available on our website . \n",
      "STATEMENT OF FINANCIAL POSITION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "“This study is a tangible example of how AI can help improve lives. It also demonstrates how AI specialists, corporate, and health sectors can work together and share their expertise to help address some of the most worrisome outcomes of COVID-19.” \n",
      "Cameron Schuler, Vector’s Chief Commercialization Ofcer \n",
      "& Vice President, Industry Innovation \n",
      "DATASET SHIFT\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "34 \n",
      "Annual Report 2021–22 Vector Institute\n",
      "SPOTLIGHT ON  \n",
      "ACCELERATING AI ADOPTION  \n",
      "IN HEALTH CARE  \n",
      "54 health clinician \n",
      "participants \n",
      "16 health care leaders \n",
      "37 Institutions\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "that TELUS applied to their data centre cooling project (see p. 14), Vector’s AI Engineering experts worked closely with TELUS on making the models available to a wider audience by publishing the work on an open-source platform. \n",
      "Similarly, the team also collaborated with researchers to \n",
      "share Vector-led research in Parameter Reduction for unseen deep architecture work through open-source. \n",
      "FOSTERING NEW WAYS TO DEPLOY AI TO \n",
      "ADDRESS CLIMATE CHANGE \n",
      "In addition to fostering responsible and trustworthy\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef217bc",
   "metadata": {},
   "source": [
    "Lastly, let's run our LLM query a final time with the reranked results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63696ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "\n",
      " I don't know. The provided text does not mention the number of Vector scholarships in AI that were awarded in 2022. It does mention the Talent and Research program, which was renewed in the federal Budget 2021 and received funding support beginning in 2022-23, but it does not provide information on scholarship awards.\n"
     ]
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "        # chain_type=\"stuff\",\n",
    "        retriever=compression_retriever)\n",
    "\n",
    "print(f\"Result:\\n\\n {qa.run(query=query)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_dataloaders",
   "language": "python",
   "name": "rag_dataloaders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
