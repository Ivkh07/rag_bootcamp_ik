{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d86f6cd",
   "metadata": {},
   "source": [
    "# Document Search with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168e6b6",
   "metadata": {},
   "source": [
    "This example shows how to use the Python [LangChain](https://python.langchain.com/docs/get_started/introduction) library to run a text-generation request on open-source LLMs and embedding models using the OpenAI SDK, then augment that request using the text stored in a collection of local PDF documents.\n",
    "\n",
    "### <u>Requirements</u>\n",
    "1. As you will accessing the LLMs and embedding models through Vector AI Engineering's Kaleidoscope Service (Vector Inference + Autoscaling), you will need to request a KScope API Key:\n",
    "\n",
    "   Run the following command (replace ```<user_id>``` and ```<password>```) from **within the cluster** to obtain the API Key. The ```access_token``` in the output is your KScope API Key.\n",
    "  ```bash\n",
    "  curl -X POST -d \"grant_type=password\" -d \"username=<user_id>\" -d \"password=<password>\" https://kscope.vectorinstitute.ai/token\n",
    "  ```\n",
    "2. After obtaining the `.env` configurations, make sure to create the ```.kscope.env``` file in your home directory (```/h/<user_id>```) and set the following env variables:\n",
    "- For local models through Kaleidoscope (KScope):\n",
    "    ```bash\n",
    "    export OPENAI_BASE_URL=\"https://kscope.vectorinstitute.ai/v1\"\n",
    "    export OPENAI_API_KEY=<kscope_api_key>\n",
    "    ```\n",
    "- For OpenAI models:\n",
    "   ```bash\n",
    "   export OPENAI_BASE_URL=\"https://api.openai.com/v1\"\n",
    "   export OPENAI_API_KEY=<openai_api_key>\n",
    "   ```\n",
    "3. (Optional) Upload some pdf files into the `source_documents` subfolder under this notebook. We have already provided some sample pdfs, but feel free to replace these with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4da1f",
   "metadata": {},
   "source": [
    "## Set up the RAG workflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cb87e-cdf4-4002-a700-77db86d0b318",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742aa343-c90c-4e4a-8099-a3fa218e256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f637730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a7448",
   "metadata": {},
   "source": [
    "#### Load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e70d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add root folder of the rag_bootcamp repo to PYTHONPATH\n",
    "current_dir = Path().resolve()\n",
    "parent_dir = current_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from utils.load_secrets import load_env_file\n",
    "load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e0bec6-a89c-4fca-a218-c784ec18e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_BASE_URL = os.environ.get(\"OPENAI_BASE_URL\")\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ecf9ac",
   "metadata": {},
   "source": [
    "#### Set up some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd4e2417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edd103",
   "metadata": {},
   "source": [
    "#### Make sure other necessary items are in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b61e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for the source_documents folder and make sure there is at least 1 pdf file here\n",
    "contains_pdf = False\n",
    "directory_path = \"./source_documents\"\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"ERROR: The {directory_path} subfolder must exist under this notebook\")\n",
    "for filename in os.listdir(directory_path):\n",
    "    contains_pdf = True if \".pdf\" in filename else contains_pdf\n",
    "if not contains_pdf:\n",
    "    print(f\"ERROR: The {directory_path} subfolder must contain at least one .pdf file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c93ad-fe81-4acd-9ea3-eca9b425ee9a",
   "metadata": {},
   "source": [
    "#### Choose LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2553d130-5b02-4852-928f-beb7ecd05d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e558afb",
   "metadata": {},
   "source": [
    "## Start with a basic generation request without RAG augmentation\n",
    "\n",
    "Let's start by asking Llama-3.1 a difficult, domain-specific question we don't expect it to have an answer to. A simple question like \"*What is the capital of France?*\" is not a good question here, because that's world knowledge that we expect the LLM to know.\n",
    "\n",
    "Instead, we want to ask it a question that is domain-specific and it won't know the answer to. A good example would be an obscure detail buried deep within a company's annual report. For example:\n",
    "\n",
    "*How many Vector scholarships in AI were awarded in 2022?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6133a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many Vector scholarships in AI were awarded in 2022?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a22c5",
   "metadata": {},
   "source": [
    "## Now send the query to the open source model using KScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00061d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "I don't have access to real-time data or specific information about the number of Vector scholarships in AI awarded in 2022. For the most accurate and up-to-date information, I recommend checking directly with Vector Institute or their official website. They would have the most current details on their scholarship programs and awards.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=GENERATOR_MODEL_NAME,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    base_url=GENERATOR_BASE_URL,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "message = [\n",
    "    (\"human\", query),\n",
    "]\n",
    "try:\n",
    "    result = llm.invoke(message)\n",
    "    print(f\"Result: \\n\\n{result.content}\")\n",
    "except Exception as err:\n",
    "    if \"Error code: 503\" in err.message:\n",
    "        print(f\"The model {GENERATOR_MODEL_NAME} is not ready yet.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1c200",
   "metadata": {},
   "source": [
    "Without additional information, Llama-3.1 is unable to answer the question correctly. **Vector in fact awarded 109 AI scholarships in 2022.** Fortunately, we do have that information available in Vector's 2021-22 Annual Report, which is available in the `source_documents` folder. Let's see how we can use RAG to augment our question with a document search and get the correct answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0255ea68",
   "metadata": {},
   "source": [
    "## Ingestion: Load and store the documents from `source_documents`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d0304",
   "metadata": {},
   "source": [
    "Start by reading in all the PDF files from `source_documents`, break them up into smaller digestible chunks, then encode them as vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "adapted-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "robust-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'11114CA Wheat Farming in Canada Industry Report.pdf'\r\n",
      "'11115CA Corn Farming in Canada Industry Report.pdf'\r\n",
      "'33639CA Auto Parts Manufacturing in Canada Industry Report.pdf'\r\n",
      "'44111CA New Car Dealers in Canada Industry Report.pdf'\r\n",
      "'48412CA Long-Distance Freight Trucking in Canada Industry Report.pdf'\r\n",
      "'48422CA Local Specialized Freight Trucking in Canada Industry Report.pdf'\r\n",
      "'48423CA Long-Distance Specialized Freight Trucking in Canada Industry Report.pdf'\r\n"
     ]
    }
   ],
   "source": [
    "ls /projects/RAG2/scotia-2/Datasets-Scotia-2/IBIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24b42902-d145-4f61-80c2-334a4b1da886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the embeddings model...\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {'device': 'cuda', 'trust_remote_code': True}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "\n",
    "print(f\"Setting up the embeddings model...\")\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=   EMBEDDING_MODEL_NAME,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5710c72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source documents: 280\n",
      "Number of text chunks: 654\n",
      "CPU times: user 9.77 s, sys: 17.3 ms, total: 9.78 s\n",
      "Wall time: 9.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the IBIS pdfs\n",
    "#directory_path = \"./source_documents\"\n",
    "directory_path = \"/projects/RAG2/scotia-2/Datasets-Scotia-2/IBIS\"\n",
    "loader = PyPDFDirectoryLoader(directory_path)\n",
    "docs = loader.load()\n",
    "print(f\"Number of source documents: {len(docs)}\")\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1250, chunk_overlap=32)\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"Number of text chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "innocent-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks2 = text_splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "simplified-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len (chunks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "intelligent-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Reuters data\n",
    "file_paths = ['/projects/RAG2/scotia-2/Datasets-Scotia-2/Agriculture_txt/agri_ca_co.csv', \n",
    "              '/projects/RAG2/scotia-2/Datasets-Scotia-2/Transport_txt/transport_CA.csv', \n",
    "              '/projects/RAG2/scotia-2/Datasets-Scotia-2/Auto_txt/auto_ca.csv', \n",
    "             ]\n",
    "def load_txt_file(file_path):\n",
    "    # Create a TextLoader instance\n",
    "\n",
    "    loader = TextLoader(file_path)\n",
    "\n",
    "    # Load the document\n",
    "\n",
    "    document = loader.load()\n",
    "    chunks2 =text_splitter.split_documents(document)\n",
    "    print(f\"Number of text chunks: {len(chunks2)}\")\n",
    "    return chunks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "altered-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 1212\n",
      "Number of text chunks: 927\n",
      "Number of text chunks: 2065\n"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths:\n",
    "    chunks2 = load_txt_file(file_path)\n",
    "    chunks= chunks +chunks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-comfort",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef3fd15-213f-4774-88e0-bbdadf28789c",
   "metadata": {},
   "source": [
    "#### Define the embeddings model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7545e",
   "metadata": {},
   "source": [
    "## Retrieval: Make the document chunks available via a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc16fe",
   "metadata": {},
   "source": [
    "The retriever will identify the document chunks that most closely match our original query. (This takes about 1-2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1048c42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 485 ms, total: 1min 52s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Retrieve the most relevant context from the vector store based on the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "neither-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#industry  = \"auto dealer\"\n",
    "industry  = \"wheat farming\"\n",
    "query = f\"Where are most {industry} companies located in Canada?\"\n",
    "query  = ' Which countries are competitors for canadian farmers internationally?' # bad\n",
    "query = 'What is the profit margin of Canadian wheat farmers' #good\n",
    "query = 'What is the profit margin of Canadian trucking companies'\n",
    "query = 'What is the profit margin of Canadian auto dealers'\n",
    "query = f'What is the profit margin of Canadian {industry}'\n",
    "query = f'What is the profit margin of Canadian {industry}'\n",
    "#query = f'Who are the main palyers in Canadian  {industry}?' # bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ethical-appointment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 ms, sys: 1e+03 ns, total: 41.1 ms\n",
      "Wall time: 38.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1690e",
   "metadata": {},
   "source": [
    "Let's see what results it found. Important to note, these results are in the order the retriever thought were the best matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "51dc81d7-8333-41e6-9e77-47a45ee0b374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Financial Benchmark s\n",
      "Key Takeaways\n",
      "Climbing whea t pric es ar e boo sting pr ofit.Whea t farmer s in Canada ha ve been be tter abl e to manage fix ed c osts and ar e using\n",
      "advanced technol ogy t o impr ove their yiel ds a t low investmen t costs.\n",
      "Purchases and depr ecia tion c osts are high f or whea t farmer s.Farmer s tha t can l ower these c osts via l ong-t erm buying c ontracts.\n",
      "Farmer s can al so impr ove profit thr ough main tenanc e agr eemen ts.\n",
      "Profit Mar gin\n",
      "15.9 % Higher than sec torAverage W age\n",
      "$16,4 24 Equal t o sec torLargest Co st\n",
      "Purchases37.9% o f\n",
      "Revenue\n",
      "Cost Struc ture Benchmark s\n",
      "Average oper ating c osts by indus try and sec tor as a shar e (%) o f revenue 202 4\n",
      "Cost Struc ture (%)\n",
      "Purchases Depr ecia tion Profit Rent Wages Mark eting Utilities Other  CostsIndus try Sec tor\n",
      "0 10 20 30 40 50 60 70 80 90 100\n",
      "Sour ce: IBIS World\n",
      "Wha t trends impac t indus try c osts?\n",
      "Whea t farmer s can pass on pur chase c osts, keeping their shar e of\n",
      "revenue s teady\n",
      "•Fertiliz er and seed pur chases ar e the l argest contribut ors to\n",
      "purchase c osts. Other pur chases incl ude chemical s and r epair s\n",
      "and main tenanc e for machines and equipmen t like tractors and\n",
      "spreader s.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "restricted the mark eting fr eedom o f farms. Demand f or Canadian\n",
      "whea t abr oad has risen because o f its reput ation f or high quality .\n",
      "Favourable pric e incr eases driv en b y world whea t pric es ha ve\n",
      "impr oved farm r evenue and pr ofitability . Impr oved tr ade ties with\n",
      "emer ging ec onomies ha ve also aided gr owth b y helping f armer s\n",
      "tap in to demand fr om ne w mark ets. Whea t farming r evenue is\n",
      "expec ted to climb a t a C AGR o f 4.7% t o an es tima ted $16.2 bil lion\n",
      "through the end o f 202 4, despit e a decr ease o f 2.5% in 202 4\n",
      "because o f waning whea t demand.\n",
      "Strong whea t pric es ha ve been the primary driv er of revenue\n",
      "growth in r ecent years. The w orld pric e of whea t grew by a\n",
      "staggering 43.3% in 2021, f ollowed b y 35.5% in 2022, as gl obal\n",
      "suppl y levels contracted. Canadian whea t pric es sur ged the same\n",
      "year amid an in tense dr ough t tha t cut cr op yiel ds, making whea t a\n",
      "rare commodity . Strong r evenue gr owth, c ombined with\n",
      "technol ogical adv ancemen ts, has enabl ed pr ofit expansion f or\n",
      "Canada 's whea t farmer s.\n",
      "Moving f orward, a c ontinued gain in the w orld pric e of whea t,\n",
      "counteracted some b y flagging demand, wil l drag do wn r evenue\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Whea t produc ts don 't ha ve a v ery high pr ofit mar gin per sal e. Farmer s can carv e out a s trong po sition in the mark et by focusing on sel ling a\n",
      "large quan tity o f whea t at a fairly low mar gin per sal e.\n",
      "Use aut oma ted pr ocedur es and pr ocesses\n",
      "Whil e farming s till relies on manual l abour , technol ogical adv ancemen ts ha ve alleviated the bur den t o a degr ee. Farms can impr ove\n",
      "efficienc y and pr oduc tion b y investing in aut oma ted equipmen t. This can incr ease scal e, which w ould aid in securing a l arger shar e of the\n",
      "mark et.\n",
      "Barrier s to En try Low Steady\n",
      "Wha t chal lenges do po tential indus try en trants face?\n",
      "Agricul ture, Forestry, Fishing and Hun ting In Canada • 11114C A\n",
      "Whea t Farming in Canada\n",
      "19 www .ibis world.com November 202 4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Legal\n",
      "•Whea t farmer s mus t compl y with al l aspec ts of the Canada Gr ain A ct, which is the l egisl ative frame work f or Canada 's grain quality\n",
      "assur ance system. F armer s ma y be r equir ed to ob tain lic ences, lik e a primary el evator lic ence.\n",
      "Start-up Co sts\n",
      "•Start-up c osts vary depending on the sc ope o f the f arm. F armer s requir e land t o begin oper ations, which is o ften the mo st significan t start-\n",
      "up c ost. Lar ger f armer s need t o invest in a tr actor or harv ester to efficien tly work their l and.\n",
      "Diff erentiation\n",
      "•Ther e is v ery littl e diff erentiation be tween whea t farmer s. Diff erences in quality ar e largely the r esul t of weather and o ther unpr edic table\n",
      "events, making al l farmer s equal ly susc eptible to a bad cr op.\n",
      "Labour Expenses\n",
      "•Canadian whea t farmer s depend mor e hea vily on capit al than l abour . Mo st than hal f of establishmen ts are nonempl oyers, which se verely\n",
      "limit s the l evel of labour in tensity . Farmer s ha ve also incr easingl y invested in ne wer, mor e costly farm equipmen t, further r educing the need\n",
      "for labour b y man y farmer s.\n",
      "Capit al Expenses\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "manageabl e. Combined with capit al in vestmen ts tha t have reduc ed farmer s' relianc e on l abour , profit has e xpanded f or Canadian whea t\n",
      "farmer s.\n",
      "•Volatile fertiliz er pric es ha ve limit ed pr ofit gr owth, though. The pric e of fertiliz er doubl ed be tween 20 19 and 2022, boo sting input c osts for\n",
      "farmer s sinc e fertiliz er is a widel y used c omponen t in agricul ture. In the y ears sinc e, this has c ome do wn some wha t.\n",
      "•Growth in pur chase c osts has been a major c oncern f or whea t farmer s in r ecent years. Co sts for other major input s, lik e seeds and supplies,\n",
      "have grown in t andem with f ertiliz er pric es.\n",
      "Volatility High\n",
      "Whea t pric es ar e de termined gl obal ly\n",
      "•Global suppl y and demand c onditions dic tate the pric e of whea t. The gl obal suppl y of whea t is the primary de terminan t of pric e, sinc e\n",
      "demand t ends t o be r elatively steady .\n",
      "•Changes in the w orld pric e of whea t have fuel led revenue v olatility in r ecent years. Strong gr owth in whea t pric es has been the primary\n",
      "contribut or to revenue gr owth.\n",
      "Weather a ffects the suppl y of whea t\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5e95e-f127-4092-b960-33b39ad21147",
   "metadata": {},
   "source": [
    "## Now send the query to the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e26d9f46-a082-4497-8ffc-9fa3eccc2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: \n",
      "\n",
      "According to the provided context, the profit margin of Canadian wheat farming is 15.9% higher than the sector average, and the average profit margin is not explicitly stated. However, it is mentioned that wheat products don't have a very high profit margin per sale, and farmers can carve out a strong position in the market by selling a large quantity of wheat at a fairly low margin per sale.\n"
     ]
    }
   ],
   "source": [
    "rag_pipeline = RetrievalQA.from_llm(llm=llm, retriever=retriever)\n",
    "result = rag_pipeline.invoke(input=query)\n",
    "print(f\"Result: \\n\\n{result['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008507b",
   "metadata": {},
   "source": [
    "The model provides the correct answer (109) using the retrieved information.\n",
    "\n",
    "But it also continues with the following 2 scenarios (as of now) due to stochasticity:\n",
    "1. It sometimes outputs another sentence which seems to be hallucinated as it gets confused between the total scholarships (351) and those awarded just in 2022.\n",
    "2. It sometimes just says *I don't know* because its not sure about the year."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_dataloaders",
   "language": "python",
   "name": "rag_dataloaders"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
